{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6ec241d-970d-47e4-a60c-93e42e08ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "408b66e2-f471-42c0-afdc-c7c60f7b7381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/12 06:05:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/12 06:05:10 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/12 06:05:10 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "25/06/12 06:05:10 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "25/06/12 06:05:10 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "25/06/12 06:05:10 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "25/06/12 06:05:10 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "25/06/12 06:05:10 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n",
      "25/06/12 06:05:10 WARN Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n",
      "25/06/12 06:05:10 WARN Utils: Service 'SparkUI' could not bind on port 4048. Attempting port 4049.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"VarunSparkWindows\").master(\"local[5]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cc38918-6cc4-4ddf-be95-44659f8da005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-32-182.ap-south-1.compute.internal:4049\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[5]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>VarunSparkWindows</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe3355baaf0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b7d7fd-d241-45d0-bf5e-61c447e74f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53a52ce0-7e31-4687-aac1-ca1ba6a07d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sch = StructType([StructField(\"name\", StringType(),True),StructField(\"department\",StringType(),True),StructField(\"salary\",IntegerType(),True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3204c753-101c-4d73-aa55-9b36cba45ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowdata = spark.read.csv('pysparkasset/windowdata.txt',sep=',', schema=sch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b61af43-ffbe-4ba9-83f6-12387562f481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+\n",
      "|   name|department|salary|\n",
      "+-------+----------+------+\n",
      "|  James|     Sales|  3000|\n",
      "|Michael|     Sales|  4600|\n",
      "| Robert|     Sales|  4100|\n",
      "|  Maria|   Finance|  3000|\n",
      "|    Ram|     Sales|  3000|\n",
      "|  Scott|   Finance|  3300|\n",
      "|    Jen|   Finance|  3900|\n",
      "|   Jeff| Marketing|  3000|\n",
      "|  Kumar| Marketing|  2000|\n",
      "| Sundar|     Sales|  4100|\n",
      "|   Amit|     Sales|  4600|\n",
      "+-------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windowdata.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0cfb833-eb56-487e-88c6-ef9d46511859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windowdata.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7413f815-4cd5-4951-825c-95c65ae9dbc2",
   "metadata": {},
   "source": [
    "### Window Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02a8b3f2-2ea1-4e8b-a733-c5cb60baf41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f132d41-6d8f-4f1e-a514-4ef5b4d06f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db7dfd90-98db-409a-b7fc-abb2f6f00c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "win1 = Window.partitionBy(\"department\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa6d2749-8f35-4b82-96b0-c608be9d9775",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf = windowdata.withColumn(\"msal\", max('salary').over(win1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d3de36d-cef3-4509-a21d-f44632ba853f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+----+\n",
      "|   name|department|salary|msal|\n",
      "+-------+----------+------+----+\n",
      "|  James|     Sales|  3000|4600|\n",
      "|Michael|     Sales|  4600|4600|\n",
      "| Robert|     Sales|  4100|4600|\n",
      "|    Ram|     Sales|  3000|4600|\n",
      "| Sundar|     Sales|  4100|4600|\n",
      "|   Amit|     Sales|  4600|4600|\n",
      "|  Maria|   Finance|  3000|3900|\n",
      "|  Scott|   Finance|  3300|3900|\n",
      "|    Jen|   Finance|  3900|3900|\n",
      "|   Jeff| Marketing|  3000|3000|\n",
      "|  Kumar| Marketing|  2000|3000|\n",
      "+-------+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a73c9cce-eb57-44d7-b254-32523d68ec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf1 = resdf.withColumn(\"diffcol\", max('salary').over(win1) - col(\"salary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df9fb47b-9c9f-4761-aa44-1724067de9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+----+-------+\n",
      "|   name|department|salary|msal|diffcol|\n",
      "+-------+----------+------+----+-------+\n",
      "|  James|     Sales|  3000|4600|   1600|\n",
      "|Michael|     Sales|  4600|4600|      0|\n",
      "| Robert|     Sales|  4100|4600|    500|\n",
      "|    Ram|     Sales|  3000|4600|   1600|\n",
      "| Sundar|     Sales|  4100|4600|    500|\n",
      "|   Amit|     Sales|  4600|4600|      0|\n",
      "|  Maria|   Finance|  3000|3900|    900|\n",
      "|  Scott|   Finance|  3300|3900|    600|\n",
      "|    Jen|   Finance|  3900|3900|      0|\n",
      "|   Jeff| Marketing|  3000|3000|      0|\n",
      "|  Kumar| Marketing|  2000|3000|   1000|\n",
      "+-------+----------+------+----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "resdf1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "826ffdcf-41a4-4adf-a28f-385553ebc72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "win2 = Window.partitionBy('department').orderBy('salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45227f85-251d-479c-b9c3-90ec7d24244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resrow = windowdata.withColumn('rnum',row_number().over(win2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8366227-dbc2-42b2-877c-be5c9005ff46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+----+\n",
      "|   name|department|salary|rnum|\n",
      "+-------+----------+------+----+\n",
      "|  James|     Sales|  3000|   1|\n",
      "|    Ram|     Sales|  3000|   2|\n",
      "| Robert|     Sales|  4100|   3|\n",
      "| Sundar|     Sales|  4100|   4|\n",
      "|Michael|     Sales|  4600|   5|\n",
      "|   Amit|     Sales|  4600|   6|\n",
      "|  Maria|   Finance|  3000|   1|\n",
      "|  Scott|   Finance|  3300|   2|\n",
      "|    Jen|   Finance|  3900|   3|\n",
      "|  Kumar| Marketing|  2000|   1|\n",
      "|   Jeff| Marketing|  3000|   2|\n",
      "+-------+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resrow.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a2cfd8d-b599-42ea-a4de-a144b50090c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rankrow = windowdata.withColumn('ranknum',rank().over(win2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3eb17de-8d75-417e-a244-f266a5f0244f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+-------+\n",
      "|   name|department|salary|ranknum|\n",
      "+-------+----------+------+-------+\n",
      "|  James|     Sales|  3000|      1|\n",
      "|    Ram|     Sales|  3000|      1|\n",
      "| Robert|     Sales|  4100|      3|\n",
      "| Sundar|     Sales|  4100|      3|\n",
      "|Michael|     Sales|  4600|      5|\n",
      "|   Amit|     Sales|  4600|      5|\n",
      "|  Maria|   Finance|  3000|      1|\n",
      "|  Scott|   Finance|  3300|      2|\n",
      "|    Jen|   Finance|  3900|      3|\n",
      "|  Kumar| Marketing|  2000|      1|\n",
      "|   Jeff| Marketing|  3000|      2|\n",
      "+-------+----------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rankrow.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a27972f-da51-4a29-93d0-c61c09c36538",
   "metadata": {},
   "outputs": [],
   "source": [
    "denserankrow = windowdata.withColumn('ranknum',dense_rank().over(win2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8bb6b58-3ccf-4803-8617-4ce7d49b9b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+-------+\n",
      "|   name|department|salary|ranknum|\n",
      "+-------+----------+------+-------+\n",
      "|  James|     Sales|  3000|      1|\n",
      "|    Ram|     Sales|  3000|      1|\n",
      "| Robert|     Sales|  4100|      2|\n",
      "| Sundar|     Sales|  4100|      2|\n",
      "|Michael|     Sales|  4600|      3|\n",
      "|   Amit|     Sales|  4600|      3|\n",
      "|  Maria|   Finance|  3000|      1|\n",
      "|  Scott|   Finance|  3300|      2|\n",
      "|    Jen|   Finance|  3900|      3|\n",
      "|  Kumar| Marketing|  2000|      1|\n",
      "|   Jeff| Marketing|  3000|      2|\n",
      "+-------+----------+------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "denserankrow.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76409521-fe1b-4e9d-82d8-8ac968222b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "leadrow = windowdata.withColumn('leadsal',lead(\"salary\").over(win2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67340b09-f2be-4eca-939e-29277a6be86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+-------+\n",
      "|   name|department|salary|leadsal|\n",
      "+-------+----------+------+-------+\n",
      "|  James|     Sales|  3000|   3000|\n",
      "|    Ram|     Sales|  3000|   4100|\n",
      "| Robert|     Sales|  4100|   4100|\n",
      "| Sundar|     Sales|  4100|   4600|\n",
      "|Michael|     Sales|  4600|   4600|\n",
      "|   Amit|     Sales|  4600|   null|\n",
      "|  Maria|   Finance|  3000|   3300|\n",
      "|  Scott|   Finance|  3300|   3900|\n",
      "|    Jen|   Finance|  3900|   null|\n",
      "|  Kumar| Marketing|  2000|   3000|\n",
      "|   Jeff| Marketing|  3000|   null|\n",
      "+-------+----------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leadrow.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "139a2d2c-2d06-491b-8e36-342f42b093ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "lagrow = windowdata.withColumn('lagnum',lag(\"salary\").over(win2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1c0d7fdc-bf46-4995-9ac6-6d57438d43c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+------+\n",
      "|   name|department|salary|lagnum|\n",
      "+-------+----------+------+------+\n",
      "|  James|     Sales|  3000|  null|\n",
      "|    Ram|     Sales|  3000|  3000|\n",
      "| Robert|     Sales|  4100|  3000|\n",
      "| Sundar|     Sales|  4100|  4100|\n",
      "|Michael|     Sales|  4600|  4100|\n",
      "|   Amit|     Sales|  4600|  4600|\n",
      "|  Maria|   Finance|  3000|  null|\n",
      "|  Scott|   Finance|  3300|  3000|\n",
      "|    Jen|   Finance|  3900|  3300|\n",
      "|  Kumar| Marketing|  2000|  null|\n",
      "|   Jeff| Marketing|  3000|  2000|\n",
      "+-------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lagrow.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42204367-c1ad-419f-b1d0-4077248a51b3",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b3bb5ac-634e-4ec0-a9ec-7e1b1ef88c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "purple = spark.read.format('text').load('purplecow.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "205e6c3a-d2da-4d9e-943d-8631d97a16c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|I've never seen a...|\n",
      "|I never hope to s...|\n",
      "|But I can tell yo...|\n",
      "|I'd rather see th...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "purple.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c7088e38-92df-4de1-8f10-bf8f098eee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = purple.select(explode(split(\"value\",' ')).alias('words'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9a14cf83-9f99-4a57-9b82-e8bc73234540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|  words|\n",
      "+-------+\n",
      "|   I've|\n",
      "|  never|\n",
      "|   seen|\n",
      "|      a|\n",
      "| purple|\n",
      "|   cow.|\n",
      "|      I|\n",
      "|  never|\n",
      "|   hope|\n",
      "|     to|\n",
      "|    see|\n",
      "|   one;|\n",
      "|    But|\n",
      "|      I|\n",
      "|    can|\n",
      "|   tell|\n",
      "|   you,|\n",
      "|anyhow,|\n",
      "|    I'd|\n",
      "| rather|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0b242c-a05a-415e-8b6c-262288e3acab",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "42973c62-12df-4887-8ae8-90f7b07a2632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|  words|count|\n",
      "+-------+-----+\n",
      "|   hope|    1|\n",
      "|    But|    1|\n",
      "|    I'd|    1|\n",
      "|   cow.|    1|\n",
      "|   seen|    1|\n",
      "|    can|    1|\n",
      "| rather|    1|\n",
      "|   tell|    1|\n",
      "|anyhow,|    1|\n",
      "|     be|    1|\n",
      "|   than|    1|\n",
      "|   one.|    1|\n",
      "| purple|    1|\n",
      "|   I've|    1|\n",
      "|   you,|    1|\n",
      "|   one;|    1|\n",
      "|    see|    2|\n",
      "|  never|    2|\n",
      "|      I|    2|\n",
      "|      a|    1|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('words').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b17d51-8f38-4c14-8069-3167a48ed7cb",
   "metadata": {},
   "source": [
    "posexplode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73944e87-aad6-46c4-b806-53c586f47921",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c9c94e-df0d-4869-bc5a-94e63df6c0d1",
   "metadata": {},
   "source": [
    "## User-Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ef7fc927-fdae-4691-9a4a-2a2002189ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def touppercases(x):\n",
    "    return x.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1003cc43-e3cd-48fd-aab9-f7e0d09a0baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INDIA'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "touppercases('india')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa865683-8a85-403a-98aa-1c90b1ab1e97",
   "metadata": {},
   "source": [
    "### Steps to write UDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db506098-ff38-4d89-be15-c537b32ed9cf",
   "metadata": {},
   "source": [
    "- create a UDF using python\n",
    "- Register UDF with spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e5a4d43f-c7ce-4741-aa3c-0ff0f4877716",
   "metadata": {},
   "outputs": [],
   "source": [
    "myucase = udf(lambda x:touppercases(x),StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d7aba62f-8e5e-4895-8cd0-6d0144496296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+-------+\n",
      "|   name|department|salary|     uc|\n",
      "+-------+----------+------+-------+\n",
      "|  James|     Sales|  3000|  JAMES|\n",
      "|Michael|     Sales|  4600|MICHAEL|\n",
      "| Robert|     Sales|  4100| ROBERT|\n",
      "|  Maria|   Finance|  3000|  MARIA|\n",
      "|    Ram|     Sales|  3000|    RAM|\n",
      "|  Scott|   Finance|  3300|  SCOTT|\n",
      "|    Jen|   Finance|  3900|    JEN|\n",
      "|   Jeff| Marketing|  3000|   JEFF|\n",
      "|  Kumar| Marketing|  2000|  KUMAR|\n",
      "| Sundar|     Sales|  4100| SUNDAR|\n",
      "|   Amit|     Sales|  4600|   AMIT|\n",
      "+-------+----------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windowdata.withColumn('uc',myucase(col('name'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1b5b8191-e738-4bae-bf4d-c80c0f295b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowdata.createOrReplaceTempView('employee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cac79f31-4bd9-4247-8b28-f6b698fc0997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.touppercases(x)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register(\"uppcase\",touppercases,StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7f8be1e6-fc08-483f-b9aa-0e07a48ee672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|   name|uppcase(name)|\n",
      "+-------+-------------+\n",
      "|  James|        JAMES|\n",
      "|Michael|      MICHAEL|\n",
      "| Robert|       ROBERT|\n",
      "|  Maria|        MARIA|\n",
      "|    Ram|          RAM|\n",
      "|  Scott|        SCOTT|\n",
      "|    Jen|          JEN|\n",
      "|   Jeff|         JEFF|\n",
      "|  Kumar|        KUMAR|\n",
      "| Sundar|       SUNDAR|\n",
      "|   Amit|         AMIT|\n",
      "+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select name,uppcase(name) from employee\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "508864ae-8b39-4409-9657-8d16e3237d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_par_part = spark.read.csv('account_parquet_csv', sep=',', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2720201a-4184-422a-bca6-395991e281b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_par_part.createTempView('acc_par_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "33cb23c1-f71c-4d49-8c3e-ce842e195d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "FileScan csv [_c0#2335,_c1#2336L,_c2#2337L,_c3#2338,_c4#2339,_c5#2340,_c6#2341,_c7#2342,_c8#2343L,_c9#2344L,_c10#2345L,state#2346] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[hdfs://master:9000/user/varunm15t38hedu/account_parquet_csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<_c0:int,_c1:bigint,_c2:bigint,_c3:string,_c4:string,_c5:string,_c6:string,_c7:int,_c8:bigi...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from acc_par_csv').explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "80d81980-7fc3-4246-beeb-3f31e3a92d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "FileScan csv [_c0#2335,_c1#2336L,_c2#2337L,_c3#2338,_c4#2339,_c5#2340,_c6#2341,_c7#2342,_c8#2343L,_c9#2344L,_c10#2345L,state#2346] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[hdfs://master:9000/user/varunm15t38hedu/account_parquet_csv], PartitionFilters: [isnotnull(state#2346), (state#2346 = CA)], PushedFilters: [], ReadSchema: struct<_c0:int,_c1:bigint,_c2:bigint,_c3:string,_c4:string,_c5:string,_c6:string,_c7:int,_c8:bigi...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ac_par_part.where(ac_par_part.state=='CA').explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "607abca2-350f-44dd-a830-80c9fe3caf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "FileScan csv [_c0#2335,_c1#2336L,_c2#2337L,_c3#2338,_c4#2339,_c5#2340,_c6#2341,_c7#2342,_c8#2343L,_c9#2344L,_c10#2345L,state#2346] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[hdfs://master:9000/user/varunm15t38hedu/account_parquet_csv], PartitionFilters: [isnotnull(state#2346), (state#2346 = CA), (state#2346 = )], PushedFilters: [], ReadSchema: struct<_c0:int,_c1:bigint,_c2:bigint,_c3:string,_c4:string,_c5:string,_c6:string,_c7:int,_c8:bigi...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ac_par_part.where(((ac_par_part.state=='CA')&(ac_par_part.state==''))).explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ce0a57-5c6e-4876-a4f7-e246dd66fc97",
   "metadata": {},
   "source": [
    "### Note: `pushed_filters` and `partition_filters` only works on dataframes in which data is not partitioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f5da4e14-5a38-4983-93fb-eee6f302e5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_par = spark.read.format('parquet').load('accounts_parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "19f18eab-9f55-40c6-b9af-74452b84f231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "* Filter (3)\n",
      "+- * ColumnarToRow (2)\n",
      "   +- Scan parquet  (1)\n",
      "\n",
      "\n",
      "(1) Scan parquet \n",
      "Output [1]: [state#2699]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [hdfs://master:9000/user/varunm15t38hedu/accounts_parquet]\n",
      "PushedFilters: [IsNotNull(state), EqualTo(state,CA)]\n",
      "ReadSchema: struct<state:string>\n",
      "\n",
      "(2) ColumnarToRow [codegen id : 1]\n",
      "Input [1]: [state#2699]\n",
      "\n",
      "(3) Filter [codegen id : 1]\n",
      "Input [1]: [state#2699]\n",
      "Condition : (isnotnull(state#2699) AND (state#2699 = CA))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ac_par.where(ac_par.state=='CA').select('state').explain('formatted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4b82997b-ef22-4fa5-a552-102dffd4d337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "* HashAggregate (5)\n",
      "+- Exchange (4)\n",
      "   +- * HashAggregate (3)\n",
      "      +- * ColumnarToRow (2)\n",
      "         +- Scan parquet  (1)\n",
      "\n",
      "\n",
      "(1) Scan parquet \n",
      "Output [1]: [state#2699]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [hdfs://master:9000/user/varunm15t38hedu/accounts_parquet]\n",
      "ReadSchema: struct<state:string>\n",
      "\n",
      "(2) ColumnarToRow [codegen id : 1]\n",
      "Input [1]: [state#2699]\n",
      "\n",
      "(3) HashAggregate [codegen id : 1]\n",
      "Input [1]: [state#2699]\n",
      "Keys [1]: [state#2699]\n",
      "Functions [1]: [partial_count(1)]\n",
      "Aggregate Attributes [1]: [count#2870L]\n",
      "Results [2]: [state#2699, count#2871L]\n",
      "\n",
      "(4) Exchange\n",
      "Input [2]: [state#2699, count#2871L]\n",
      "Arguments: hashpartitioning(state#2699, 200), ENSURE_REQUIREMENTS, [id=#991]\n",
      "\n",
      "(5) HashAggregate [codegen id : 2]\n",
      "Input [2]: [state#2699, count#2871L]\n",
      "Keys [1]: [state#2699]\n",
      "Functions [1]: [count(1)]\n",
      "Aggregate Attributes [1]: [count(1)#2866L]\n",
      "Results [2]: [state#2699, count(1)#2866L AS count#2867L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ac_par.groupBy('state').count().explain('formatted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4867c195-2bfe-43ce-97b6-eae700b38082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[state#2346], functions=[count(1)])\n",
      "+- Exchange hashpartitioning(state#2346, 200), ENSURE_REQUIREMENTS, [id=#881]\n",
      "   +- *(1) HashAggregate(keys=[state#2346], functions=[partial_count(1)])\n",
      "      +- FileScan csv [state#2346] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[hdfs://master:9000/user/varunm15t38hedu/account_parquet_csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ac_par_part.groupBy('state').count().explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fd25f570-7853-4e59-8eb3-74ac73e26d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl = spark.read.json('pysparkasset/people.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b5e39606-a3f6-403a-b1df-bca9685fd743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) BroadcastHashJoin [pcode#2789], [zipcode#2700], Inner, BuildLeft, false\n",
      ":- BroadcastExchange HashedRelationBroadcastMode(List(input[2, string, false]),false), [id=#916]\n",
      ":  +- *(1) Filter isnotnull(pcode#2789)\n",
      ":     +- FileScan json [age#2787L,name#2788,pcode#2789] Batched: false, DataFilters: [isnotnull(pcode#2789)], Format: JSON, Location: InMemoryFileIndex[hdfs://master:9000/user/varunm15t38hedu/pysparkasset/people.json], PartitionFilters: [], PushedFilters: [IsNotNull(pcode)], ReadSchema: struct<age:bigint,name:string,pcode:string>\n",
      "+- *(2) Filter isnotnull(zipcode#2700)\n",
      "   +- *(2) ColumnarToRow\n",
      "      +- FileScan parquet [acct_num#2692,acct_create_dt#2693L,acct_close_dt#2694L,first_name#2695,last_name#2696,address#2697,city#2698,state#2699,zipcode#2700,phone_number#2701,created#2702L,modified#2703L] Batched: true, DataFilters: [isnotnull(zipcode#2700)], Format: Parquet, Location: InMemoryFileIndex[hdfs://master:9000/user/varunm15t38hedu/accounts_parquet], PartitionFilters: [], PushedFilters: [IsNotNull(zipcode)], ReadSchema: struct<acct_num:int,acct_create_dt:bigint,acct_close_dt:bigint,first_name:string,last_name:string...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ppl.join(ac_par, ppl.pcode==ac_par.zipcode,\"inner\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0ed27496-5d90-4e91-aee2-593a73740def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "* BroadcastHashJoin Inner BuildLeft (7)\n",
      ":- BroadcastExchange (3)\n",
      ":  +- * Filter (2)\n",
      ":     +- Scan json  (1)\n",
      "+- * Filter (6)\n",
      "   +- * ColumnarToRow (5)\n",
      "      +- Scan parquet  (4)\n",
      "\n",
      "\n",
      "(1) Scan json \n",
      "Output [3]: [age#2787L, name#2788, pcode#2789]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [hdfs://master:9000/user/varunm15t38hedu/pysparkasset/people.json]\n",
      "PushedFilters: [IsNotNull(pcode)]\n",
      "ReadSchema: struct<age:bigint,name:string,pcode:string>\n",
      "\n",
      "(2) Filter [codegen id : 1]\n",
      "Input [3]: [age#2787L, name#2788, pcode#2789]\n",
      "Condition : isnotnull(pcode#2789)\n",
      "\n",
      "(3) BroadcastExchange\n",
      "Input [3]: [age#2787L, name#2788, pcode#2789]\n",
      "Arguments: HashedRelationBroadcastMode(List(input[2, string, false]),false), [id=#951]\n",
      "\n",
      "(4) Scan parquet \n",
      "Output [12]: [acct_num#2692, acct_create_dt#2693L, acct_close_dt#2694L, first_name#2695, last_name#2696, address#2697, city#2698, state#2699, zipcode#2700, phone_number#2701, created#2702L, modified#2703L]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [hdfs://master:9000/user/varunm15t38hedu/accounts_parquet]\n",
      "PushedFilters: [IsNotNull(zipcode)]\n",
      "ReadSchema: struct<acct_num:int,acct_create_dt:bigint,acct_close_dt:bigint,first_name:string,last_name:string,address:string,city:string,state:string,zipcode:string,phone_number:string,created:bigint,modified:bigint>\n",
      "\n",
      "(5) ColumnarToRow\n",
      "Input [12]: [acct_num#2692, acct_create_dt#2693L, acct_close_dt#2694L, first_name#2695, last_name#2696, address#2697, city#2698, state#2699, zipcode#2700, phone_number#2701, created#2702L, modified#2703L]\n",
      "\n",
      "(6) Filter\n",
      "Input [12]: [acct_num#2692, acct_create_dt#2693L, acct_close_dt#2694L, first_name#2695, last_name#2696, address#2697, city#2698, state#2699, zipcode#2700, phone_number#2701, created#2702L, modified#2703L]\n",
      "Condition : isnotnull(zipcode#2700)\n",
      "\n",
      "(7) BroadcastHashJoin [codegen id : 2]\n",
      "Left keys [1]: [pcode#2789]\n",
      "Right keys [1]: [zipcode#2700]\n",
      "Join condition: None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ppl.join(ac_par, ppl.pcode==ac_par.zipcode,\"inner\").explain('formatted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b63256e-a01f-49be-87ef-e881525a238d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark 3",
   "language": "python",
   "name": "pyspark3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
